{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Fooling models with adversarial examples**\n",
        "\n",
        "In this homework assignment, you will be crafting an adversarial attack to fool a simple machine learning model. The code for training the model is provided, so you will only be writing the code for a FGSM/PGD attack. After creating your attack, you will use it to measure the model prediction accuracy under several different attack parameters.\n",
        "\n",
        "This assignment can be completed on Google Colab. Since there is some model training done, the free GPU can help speed up the process. To use one, you can click the down arrow in the top right of the page and select the \"Change runtime type\" option. From here, the T4 GPU can be selected. This is optional to do given the simplicity of the model, since the overall training will not take very long on the\n",
        " non-GPU version.\n",
        "\n",
        "<br>\n",
        "\n",
        "The PGD attack is formulated as:\n",
        "\n",
        "$x_{adv}^{t+1}=\\mathcal{P}(x_{adv}^{t}+\\alpha*sign[∇_{x_{adv}^{t}}\\mathcal{L(\\theta,x_{adv}^{t},y)}])   \\text{ where the attack is constrained by } ||x_{adv}-x|| \\leq ɛ$.\n",
        "\n",
        "<br>\n",
        "\n",
        "The PGD attack is an iterative, multi-step attack. The attack is described below.\n",
        "\n",
        "- For the initialization, $X_{adv}^0=x$ will be used.\n",
        "\n",
        "- $\\mathcal{L}(\\theta,x_{adv}^t,y)$ refers to the loss of the model on the adversarial example $x_{adv}^{t}$. The attack will use the gradient of $x_{adv}^{t}$ with respect to this loss $∇_{x_{adv}^{t}}\\mathcal{L(\\theta,x_{adv}^{t},y)}$ to update the adversarial example.\n",
        "\n",
        "- For each step in the attack, the $sign$ of the gradient will be used with a step of size $\\alpha$ for the update. The step size $\\alpha$ will vary based on the total number of steps used by the attack.\n",
        "\n",
        "- After each step, a projection operation $\\mathcal{P}$ is applied to ensure that each pixel of $x_{adv}^{t}$ is no more than $\\varepsilon$ away from the original image $x$ (in practice, this can be done by clipping the image).\n",
        "\n",
        "- The adversarial example will also be constrained to be within the bounds of a natural image [0, 1] (also through clipping).\n",
        "\n",
        "<br>\n",
        "\n",
        "The code below creates a simple CNN model and trains it on CIFAR-10 for 20 epochs. The code can be run without any modification."
      ],
      "metadata": {
        "id": "DJvw4xnjb9ED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgWfGnoVFzXo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(64*4*4, 256)\n",
        "    self.fc2 = nn.Linear(256, num_classes)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return(x)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='data', train=True, transform=transform, download=True)\n",
        "testset  = torchvision.datasets.CIFAR10(root='data', train=False, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=1, pin_memory=True)\n",
        "testloader  = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1, pin_memory=True)\n",
        "\n",
        "plt.imshow(trainset[0][0].permute(1,2,0))\n",
        "plt.title('Training image')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN(num_classes=10).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  total_correct_train, total_samples, total_loss, total_batches = 0, 0, 0, 0\n",
        "\n",
        "  for X, Y in (pbar := tqdm(trainloader, ncols=1000)):\n",
        "    X, Y = X.to(device), Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, Y)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_batches += 1\n",
        "    total_correct_train += (pred.argmax(dim=1) == Y).sum()\n",
        "    total_samples += X.shape[0]\n",
        "\n",
        "    average_loss = total_loss/total_batches\n",
        "    train_acc = total_correct_train*100/total_samples\n",
        "\n",
        "    pbar.set_description(f\"{epoch+1}/{epochs}   {average_loss=:.04e}  {train_acc=:.02f}%\")\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  total_correct, total_samples, test_acc = 0, 0, 0\n",
        "\n",
        "  for X, Y in (pbar := tqdm(testloader, ncols=1000)):\n",
        "    X, Y = X.to(device), Y.to(device)\n",
        "    total_samples += X.shape[0]\n",
        "\n",
        "    with torch.no_grad(): pred = model(X)\n",
        "    total_correct += (pred.argmax(dim=1) == Y).sum()\n",
        "\n",
        "    test_acc = total_correct*100/total_samples\n",
        "\n",
        "    pbar.set_description(f\"{epoch+1}/{epochs}   {test_acc=:.02f}%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating an adversarial attack**\n",
        "\n",
        "Below you will find a basic template for creating the adversarial attack. Please fill out the below function where indicated.\n",
        "\n",
        "<br>\n",
        "\n",
        "***Details:***\n",
        "\n",
        "We will vary the step size based on the number of steps. Recall that it is okay for any step to go beyond the boundary of $ɛ$, since it will be projected back to the $ɛ$ boundary.\n",
        "\n",
        "- If the number of steps $= 1$, $\\alpha = ɛ$\n",
        "- If the number of steps $>1$ but $<4$, $\\alpha = \\frac{ɛ}{\\text{num_steps}-1}$\n",
        "- If the number of steps $\\geq 4$, $\\alpha = \\frac{eps}{4}$\n",
        "\n",
        "For the adversarial example generation, you will need to implement a few parts. Please look at the code for individual hints. For each step in the attack, you will need to:\n",
        "\n",
        "- Compute the loss on the X_adv\n",
        "- Compute the gradient of X_adv using this loss\n",
        "- Update the X_adv using the sign of the gradient\n",
        "- Clip the difference between X and X_adv to be $\\leqɛ$\n",
        "- Clip X_adv to being between [0, 1]\n",
        "\n",
        "<br>\n",
        "\n",
        "***Verification***\n",
        "\n",
        "The code at the bottom evaluates the model on your PGD attack with $\\varepsilon=\\frac{8}{255}$ and 10 steps. If the implementation is correct, the accuracy of the model against the attack should be very low (around 5% or less)."
      ],
      "metadata": {
        "id": "9ZA7EGi7naE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(model=None, X=None, Y=None, eps:float=8./255, num_steps=10):\n",
        "  \"\"\"\n",
        "  this pgd assumes the data passed to it is in the range of [0,1]\n",
        "  \"\"\"\n",
        "\n",
        "  # Here we define the loss used. Since we are working with a classification\n",
        "  # task, we will use the CrossEntropyLoss.\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "\n",
        "  # First create a copy of the original training data. Requires_grad is set to\n",
        "  # True, since the gradient of the image will need to be computed.\n",
        "  X_adv = X.clone().detach().requires_grad_(True)\n",
        "\n",
        "  # The model parameter gradient computation is turned off for the optimization\n",
        "  # since we will not need it.\n",
        "  requires_grad_list = []\n",
        "  for p in model.parameters():\n",
        "    requires_grad_list.append(p.requires_grad)\n",
        "    p.requires_grad_(False)\n",
        "\n",
        "  # ------------------------ [FILL IN CODE HERE] ------------------------------\n",
        "\n",
        "  # The step size of the attack is chosen based on the number of steps taken.\n",
        "  # ---- Fill this in ---- #\n",
        "\n",
        "\n",
        "  # Here, is the main part of the adversarial attack.\n",
        "  # ---- Fill this in ---- #\n",
        "  for _ in range(num_steps):\n",
        "    X_adv.grad = None\n",
        "\n",
        "    # Calculate the loss on the current adversarial example.\n",
        "    # Hint, use the \"loss\" we defined before.\n",
        "    # ---- Fill this in ---- #\n",
        "\n",
        "\n",
        "    # Compute the gradient on the adversarial image using the previous output\n",
        "    # of the loss. Hint, use the .backward() operation in PyTorch.\n",
        "    # ---- Fill this in ---- #\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # Update the adversarial example by taking a step in the direction of the\n",
        "      # sign of the gradient of the image X_adv. Use the step_size you defined\n",
        "      # previously.\n",
        "      # ---- Fill this in ---- #\n",
        "\n",
        "\n",
        "      # Clip the difference between X and X_adv to be within eps of each other.\n",
        "      # Hint, use torch.clamp()\n",
        "      # ---- Fill this in ---- #\n",
        "\n",
        "\n",
        "      # Clip the adversarial image to be between [0, 1].\n",
        "      # ---- Fill this in ---- #\n",
        "\n",
        "\n",
        "  # ---------------------------------------------------------------------------\n",
        "\n",
        "  # Reset the model\n",
        "  for p, b in zip(model.parameters(), requires_grad_list):\n",
        "    p.grad = None\n",
        "    p.requires_grad_(b)\n",
        "\n",
        "  # reset model state\n",
        "  X_adv.requires_grad_(False)\n",
        "  return X_adv.detach()\n",
        "\n",
        "\n",
        "def evaluate_adv(model=None, testloader=None, eps=(8/255.), num_steps=10):\n",
        "  '''\n",
        "  This function evaluates the model using the attack parameters provided. The\n",
        "  accuracy against the adversarial attack is returned along with the total\n",
        "  correct and wrong prediction. No modification is necessary.\n",
        "  '''\n",
        "  total_samples, adv_correct, adv_acc = 0, 0, 0\n",
        "\n",
        "  for X, Y in iter(testloader):\n",
        "    X, Y = X.to(device), Y.to(device)\n",
        "    total_samples += X.shape[0]\n",
        "\n",
        "    if eps != 0:\n",
        "      X_adv = pgd(model, X, Y, eps, num_steps)\n",
        "    else:\n",
        "      X_adv = X\n",
        "\n",
        "    with torch.no_grad(): pred = model(X_adv)\n",
        "    adv_correct += (pred.argmax(dim=1) == Y).sum()\n",
        "    adv_acc = adv_correct*100/total_samples\n",
        "\n",
        "  return adv_acc, adv_correct, total_samples-adv_correct\n",
        "\n",
        "\n",
        "adv_acc, correct, wrong = evaluate_adv(model, testloader, eps=(8/255.), num_steps=10)\n",
        "\n",
        "print(\"Correct: %i  \\nWrong: %i \\nTotal:  %i  \\nThe adversarial accuracy is: %.2f  \" % (correct.item(), wrong.item(), correct.item()+wrong.item(),  adv_acc.item()))"
      ],
      "metadata": {
        "id": "AgR5zyLMkA8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experimenting with the attack**\n",
        "\n",
        "Now that the attack is implemented, let's experiment with it. Run the attack with some different hyperparameters and report the results. Suggestions for the values are given, but feel free to experiment with other values. Matplotlib can be used to plot the results.\n",
        "\n",
        "- Plot the model accuracy when varying $\\varepsilon$ ($\\frac{0}{255} - \\frac{16}{255}$) while keeping the number of steps fixed at 10.\n",
        "\n",
        "- Plot the model accuracy when varying the number of attack steps (1 - 10) while keeping the epsilon fixed at 8/255.\n",
        "\n",
        "- Plot images with different $\\varepsilon$ ($\\frac{0}{255} - \\frac{30}{255}$, plotting every other value). Keep the number of steps fixed at 10."
      ],
      "metadata": {
        "id": "YTeI6FZutMVO"
      }
    }
  ]
}